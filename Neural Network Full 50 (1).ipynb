{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/envs/py3env/lib/python3.5/site-packages (2.2.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.0.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: h5py in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, Nadam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = pd.read_csv('resampled_df_40')\n",
    "\n",
    "resampled_df = resampled_df.drop(resampled_df.columns[0], axis = 1)\n",
    "response='TARGET'\n",
    "predictors= [col for col in resampled_df.columns if col != response]\n",
    "X_resampled = resampled_df[predictors]\n",
    "y_resampled = resampled_df[response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_grid = {'lr': np.linspace(0.001, 0.01, 15),\n",
    "     'first_neuron': np.random.randint(100, 500, 5),\n",
    "     'second_neuron': np.random.randint(100,300,5),\n",
    "     'third_neuron': np.random.randint(100,300,5),\n",
    "     'hidden_layers':[1,2,3],\n",
    "     'batch_size': [50, 100, 200],\n",
    "     'epochs': [20, 30, 40, 50, 60, 70, 80, 90,100],\n",
    "     'dropout': np.linspace(0, 0.5, 10),\n",
    "     # 'weight_regularizer':np.linspace(0.01, 0.5, 10),\n",
    "     'optimizer': [Nadam, RMSprop, SGD],\n",
    "     'activation':['relu', 'elu', 'tanh'],\n",
    "     'kernel_initializer':['glorot_uniform', 'normal', 'VarianceScaling', 'lecun_uniform']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(X_resampled.columns)\n",
    "\n",
    "def build_network(first_neuron, second_neuron, third_neuron, activation, dropout, optimizer, hidden_layers, lr, kernel_initializer):\n",
    "\n",
    "    # next we can build the model exactly like we would normally do it\n",
    "    model = Sequential()\n",
    "    model.add(Dense(first_neuron, input_dim=n_features, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    # if we want to also test for number of layers and shapes, that's possible\n",
    "    if hidden_layers == 2:\n",
    "        model.add(Dense(second_neuron, kernel_initializer=kernel_initializer))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "    elif hidden_layers == 3:\n",
    "        model.add(Dense(second_neuron, kernel_initializer=kernel_initializer))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(third_neuron, kernel_initializer=kernel_initializer))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "   \n",
    "    # then we finish again with completely standard Keras way\n",
    "    model.add(Dense(1, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    optimizer1 = optimizer(lr = lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run if you want the results\n",
    "\n",
    "# %%time\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# kf = StratifiedKFold(n_splits = 2)\n",
    "\n",
    "# estimator = KerasClassifier(build_fn = build_network, verbose = 0)\n",
    "# random = RandomizedSearchCV(estimator, keras_grid, n_iter = 60, scoring='roc_auc', cv = kf, return_train_score=False, n_jobs=-1, verbose = True)\n",
    "\n",
    "# results_nn = random.fit(X_resampled, y_resampled)\n",
    "# nn_random = pd.DataFrame(results_nn.cv_results_)\n",
    "# nn_random.to_csv('NN_random_results2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_random_results = pd.read_csv('NN_random_results2').sort_values('mean_test_score', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def reg_sub(string_example):\n",
    "  my_string = re.sub(r\"('optimizer.+>,)\", \"\", string_example)\n",
    "  return my_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn = build_network, verbose = 0)\n",
    "NN_clf = estimator.set_params(optimizer = SGD, **ast.literal_eval( reg_sub(NN_random_results['params'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def true_neg_rate(y_true, y_pred):\n",
    "  c_mat = confusion_matrix(y_true, y_pred)\n",
    "  return c_mat[0,0]/(c_mat[0,0] + c_mat[0,1])\n",
    "\n",
    "c_mat = {'TNR': make_scorer(true_neg_rate), 'TPR':'recall', 'Acc': 'accuracy', 'AUC':'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 59s, sys: 6min 28s, total: 37min 27s\n",
      "Wall time: 12min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 12.7min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "columns = ['TNR', 'TPR', 'Accuracy', 'AUC', 'Loss']\n",
    "results = pd.DataFrame(0.0, columns=columns, index = ['NN_Random_clf']) \n",
    "kf = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "m_scores = cross_validate(NN_clf, X_resampled, y_resampled, cv = kf, scoring=c_mat, return_train_score= False, verbose=True)\n",
    "results.loc['NN_Random_clf','TNR'] = np.mean(m_scores['test_TNR'])\n",
    "results.loc['NN_Random_clf', 'TPR'] = np.mean(m_scores['test_TPR'])\n",
    "results.loc['NN_Random_clf', 'Accuracy'] = np.mean(m_scores['test_Acc'])\n",
    "results.loc['NN_Random_clf', 'AUC'] = np.mean(m_scores['test_AUC'])\n",
    "results.loc['NN_Random_clf', 'Loss'] = -(1-results.loc['NN_Random_clf','TNR'])*2417 -(1-results.loc['NN_Random_clf', 'TPR'])*1124\n",
    "    \n",
    "results = results.round(3)\n",
    "results.to_csv('NN_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TNR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN_Random_clf</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.741</td>\n",
       "      <td>-1007.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TNR   TPR  Accuracy    AUC      Loss\n",
       "NN_Random_clf  0.802  0.53      0.69  0.741 -1007.934"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
